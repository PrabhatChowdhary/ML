{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f06b5d51",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-10-20T09:41:37.502303Z",
     "iopub.status.busy": "2022-10-20T09:41:37.501365Z",
     "iopub.status.idle": "2022-10-20T09:41:37.520527Z",
     "shell.execute_reply": "2022-10-20T09:41:37.518605Z"
    },
    "papermill": {
     "duration": 0.034682,
     "end_time": "2022-10-20T09:41:37.524747",
     "exception": false,
     "start_time": "2022-10-20T09:41:37.490065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/prudential-life-insurance-assessment/train.csv.zip\n",
      "/kaggle/input/prudential-life-insurance-assessment/sample_submission.csv.zip\n",
      "/kaggle/input/prudential-life-insurance-assessment/test.csv.zip\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d498f46b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T09:41:37.543881Z",
     "iopub.status.busy": "2022-10-20T09:41:37.543261Z",
     "iopub.status.idle": "2022-10-20T09:41:38.550577Z",
     "shell.execute_reply": "2022-10-20T09:41:38.549447Z"
    },
    "papermill": {
     "duration": 1.020063,
     "end_time": "2022-10-20T09:41:38.553294",
     "exception": false,
     "start_time": "2022-10-20T09:41:37.533231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('../input/prudential-life-insurance-assessment/train.csv.zip')\n",
    "scoring_data=pd.read_csv('../input/prudential-life-insurance-assessment/test.csv.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0d7e35",
   "metadata": {
    "papermill": {
     "duration": 0.010294,
     "end_time": "2022-10-20T09:41:38.572324",
     "exception": false,
     "start_time": "2022-10-20T09:41:38.562030",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "****check for nan in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1a776ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T09:41:38.591640Z",
     "iopub.status.busy": "2022-10-20T09:41:38.590734Z",
     "iopub.status.idle": "2022-10-20T09:41:38.624457Z",
     "shell.execute_reply": "2022-10-20T09:41:38.622315Z"
    },
    "papermill": {
     "duration": 0.047519,
     "end_time": "2022-10-20T09:41:38.628527",
     "exception": false,
     "start_time": "2022-10-20T09:41:38.581008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c7d962",
   "metadata": {
    "papermill": {
     "duration": 0.010062,
     "end_time": "2022-10-20T09:41:38.649846",
     "exception": false,
     "start_time": "2022-10-20T09:41:38.639784",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**We start by analysing number of nulls **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "412a6b84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T09:41:38.673398Z",
     "iopub.status.busy": "2022-10-20T09:41:38.672951Z",
     "iopub.status.idle": "2022-10-20T09:41:38.693804Z",
     "shell.execute_reply": "2022-10-20T09:41:38.692478Z"
    },
    "papermill": {
     "duration": 0.033261,
     "end_time": "2022-10-20T09:41:38.696565",
     "exception": false,
     "start_time": "2022-10-20T09:41:38.663304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input data set is (59381, 128)\n",
      "total number of columns with all values NaN are 0\n",
      "total number of columns with atleast one NaN are 13\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of input data set is {}\".format(data.shape))\n",
    "print(\"total number of columns with all values NaN are {}\".format(data.isna().all().values.sum()))\n",
    "print(\"total number of columns with atleast one NaN are {}\".format(data.isna().any().values.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c49568",
   "metadata": {
    "papermill": {
     "duration": 0.007515,
     "end_time": "2022-10-20T09:41:38.712291",
     "exception": false,
     "start_time": "2022-10-20T09:41:38.704776",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**We see that each row has atleast one NaN but each time it belongs to a different column. So we cant use data.dropna() - that would delete all the rows. Let's find column-wise sum of all NaNs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06380c7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T09:41:38.730146Z",
     "iopub.status.busy": "2022-10-20T09:41:38.729099Z",
     "iopub.status.idle": "2022-10-20T09:41:38.758011Z",
     "shell.execute_reply": "2022-10-20T09:41:38.756821Z"
    },
    "papermill": {
     "duration": 0.040257,
     "end_time": "2022-10-20T09:41:38.760367",
     "exception": false,
     "start_time": "2022-10-20T09:41:38.720110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Employment_Info_1         19\n",
       "Employment_Info_4       6779\n",
       "Employment_Info_6      10854\n",
       "Insurance_History_5    25396\n",
       "Family_Hist_2          28656\n",
       "Family_Hist_3          34241\n",
       "Family_Hist_4          19184\n",
       "Family_Hist_5          41811\n",
       "Medical_History_1       8889\n",
       "Medical_History_10     58824\n",
       "Medical_History_15     44596\n",
       "Medical_History_24     55580\n",
       "Medical_History_32     58274\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_null=data.columns[data.isna().any()]\n",
    "data[cols_null].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821dfc2f",
   "metadata": {
    "papermill": {
     "duration": 0.007662,
     "end_time": "2022-10-20T09:41:38.775944",
     "exception": false,
     "start_time": "2022-10-20T09:41:38.768282",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**We need to decide on the number of NaN values that are accpeted in a feature that is used for training the data set** Lets choose 6000 to be the number. We need to remove all the columns with NaN values more than 6k to be removed from dataset -data.(we could also have used missing data as a feature by tagging it as zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b82dced",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T09:41:38.793646Z",
     "iopub.status.busy": "2022-10-20T09:41:38.793216Z",
     "iopub.status.idle": "2022-10-20T09:41:38.845480Z",
     "shell.execute_reply": "2022-10-20T09:41:38.843919Z"
    },
    "papermill": {
     "duration": 0.064008,
     "end_time": "2022-10-20T09:41:38.847911",
     "exception": false,
     "start_time": "2022-10-20T09:41:38.783903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_drop=data[cols_null].isna().sum()>6000\n",
    "cols_not_drop=data[cols_null].isna().sum()<6000\n",
    "\n",
    "#creating object names of columns from boolean cols_drop\n",
    "drop_col_obj=cols_drop.index[cols_drop]\n",
    "dataset=data.drop(drop_col_obj,axis=1)\n",
    "\n",
    "#we also need to replace the NaN of 'Employment_info_1' - lets replace it with the mean value of the column\n",
    "replace_col=cols_not_drop.index[cols_not_drop]\n",
    "dataset[replace_col]=dataset[replace_col].replace(np.nan,dataset[replace_col].mean())\n",
    "\n",
    "#check if we have missed any nulls\n",
    "dataset.isna().any().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb83ebf9",
   "metadata": {
    "papermill": {
     "duration": 0.007864,
     "end_time": "2022-10-20T09:41:38.863824",
     "exception": false,
     "start_time": "2022-10-20T09:41:38.855960",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Let's explore the training dataset now**. \n",
    "Here is a list of feature selection techniques that we can use-\n",
    "1. Remove features that have very low variance\n",
    "2. Remove of one of the 2 features if there is a high correlation between them.\n",
    "3. Remove features with very low correlation with the target.\n",
    "4. Add loop to go through different features and select those which provide the best results.\n",
    "5. LASSO- Least Absolute Shrinkage and Selection Order.\n",
    "6. Tree based - forest trees to evalute importance of features/PCA/ Cluster analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09241930",
   "metadata": {
    "papermill": {
     "duration": 0.008002,
     "end_time": "2022-10-20T09:41:38.880087",
     "exception": false,
     "start_time": "2022-10-20T09:41:38.872085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**First check if all features are of type int or float**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2818a732",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T09:41:38.898494Z",
     "iopub.status.busy": "2022-10-20T09:41:38.898063Z",
     "iopub.status.idle": "2022-10-20T09:41:38.918300Z",
     "shell.execute_reply": "2022-10-20T09:41:38.916832Z"
    },
    "papermill": {
     "duration": 0.0323,
     "end_time": "2022-10-20T09:41:38.920618",
     "exception": false,
     "start_time": "2022-10-20T09:41:38.888318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dtype('int64') dtype('O') dtype('float64')]\n",
      "Index(['Product_Info_2'], dtype='object')\n",
      " the number of unique items are ['D3' 'A1' 'E1' 'D4' 'D2' 'A8' 'A2' 'D1' 'A7' 'A6' 'A3' 'A5' 'C4' 'C1'\n",
      " 'B2' 'C3' 'C2' 'A4' 'B1']\n"
     ]
    }
   ],
   "source": [
    "#to find different types of datatypes used in dataset\n",
    "print(dataset.dtypes.unique())\n",
    "\n",
    "#to find which columns have datatype not as int64 or float64\n",
    "obj_col_name=dataset.select_dtypes(include=['object']).columns\n",
    "print(obj_col_name)\n",
    "\n",
    "obj_data=dataset[obj_col_name]\n",
    " \n",
    "col_one_hot=obj_data.Product_Info_2.unique()\n",
    "#to find number of unique values in the datatype which has type 'O'\n",
    "print(\" the number of unique items are\",col_one_hot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ae1db9",
   "metadata": {
    "papermill": {
     "duration": 0.007626,
     "end_time": "2022-10-20T09:41:38.936133",
     "exception": false,
     "start_time": "2022-10-20T09:41:38.928507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***We use one hot encoding to convert \"Product_Info_2\" into differenet lablels*** we are doing this before split in this case. This is debatable as it could lead to data leakage in many cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72aee646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T09:41:38.954277Z",
     "iopub.status.busy": "2022-10-20T09:41:38.953486Z",
     "iopub.status.idle": "2022-10-20T09:41:39.030099Z",
     "shell.execute_reply": "2022-10-20T09:41:39.029029Z"
    },
    "papermill": {
     "duration": 0.088888,
     "end_time": "2022-10-20T09:41:39.032851",
     "exception": false,
     "start_time": "2022-10-20T09:41:38.943963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "one_hot_enc=pd.get_dummies(obj_data.Product_Info_2)\n",
    "\n",
    "#drop the feature with type object\n",
    "dataset=dataset.drop(['Product_Info_2'],axis=1)\n",
    "\n",
    "#we can also drop the id column as it is only the serial number\n",
    "dataset=dataset.drop(['Id'],axis=1)\n",
    "\n",
    "#now we append one_hot_enc to out dataset\n",
    "dataset=pd.concat([dataset,one_hot_enc],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06af577d",
   "metadata": {
    "papermill": {
     "duration": 0.007799,
     "end_time": "2022-10-20T09:41:39.048808",
     "exception": false,
     "start_time": "2022-10-20T09:41:39.041009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Test train split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e3b06c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T09:41:39.066779Z",
     "iopub.status.busy": "2022-10-20T09:41:39.066125Z",
     "iopub.status.idle": "2022-10-20T09:41:40.394482Z",
     "shell.execute_reply": "2022-10-20T09:41:40.393297Z"
    },
    "papermill": {
     "duration": 1.34039,
     "end_time": "2022-10-20T09:41:40.397335",
     "exception": false,
     "start_time": "2022-10-20T09:41:39.056945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#first split dataset into X and y\n",
    "X= dataset.drop(['Response'],axis=1)\n",
    "\n",
    "y= dataset['Response']\n",
    "\n",
    "#now split X,y into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.33,random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c0519f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T09:41:40.416527Z",
     "iopub.status.busy": "2022-10-20T09:41:40.416067Z",
     "iopub.status.idle": "2022-10-20T09:41:40.430535Z",
     "shell.execute_reply": "2022-10-20T09:41:40.429049Z"
    },
    "papermill": {
     "duration": 0.028455,
     "end_time": "2022-10-20T09:41:40.434058",
     "exception": false,
     "start_time": "2022-10-20T09:41:40.405603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for Nan in X here\n",
    "X.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e827aa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T09:41:40.452710Z",
     "iopub.status.busy": "2022-10-20T09:41:40.452256Z",
     "iopub.status.idle": "2022-10-20T09:41:40.460734Z",
     "shell.execute_reply": "2022-10-20T09:41:40.459575Z"
    },
    "papermill": {
     "duration": 0.020444,
     "end_time": "2022-10-20T09:41:40.463102",
     "exception": false,
     "start_time": "2022-10-20T09:41:40.442658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique values of response are 8\n",
      "the unique values of response are [2 8 4 6 7 1 5 3]\n"
     ]
    }
   ],
   "source": [
    "#let's check number of unique values of 'Response'\n",
    "print('number of unique values of response are {}'.format(y_train.nunique()))\n",
    "print('the unique values of response are {}'.format(y_train.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa80e8d",
   "metadata": {
    "papermill": {
     "duration": 0.008714,
     "end_time": "2022-10-20T09:41:40.480962",
     "exception": false,
     "start_time": "2022-10-20T09:41:40.472248",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**We should check variance of each feature before applying fit transform and training the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6dea45d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T09:41:40.501288Z",
     "iopub.status.busy": "2022-10-20T09:41:40.500856Z",
     "iopub.status.idle": "2022-10-20T09:41:40.577861Z",
     "shell.execute_reply": "2022-10-20T09:41:40.576549Z"
    },
    "papermill": {
     "duration": 0.090614,
     "end_time": "2022-10-20T09:41:40.580743",
     "exception": false,
     "start_time": "2022-10-20T09:41:40.490129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical_History_2      31804.885811\n",
      "Product_Info_3            25.886860\n",
      "Employment_Info_2         17.829969\n",
      "InsuredInfo_3              7.143939\n",
      "Insurance_History_3        0.980244\n",
      "                           ...     \n",
      "Medical_Keyword_35         0.006741\n",
      "Medical_Keyword_13         0.005922\n",
      "Ht                         0.005504\n",
      "Medical_History_38         0.004604\n",
      "Medical_History_35         0.003742\n",
      "Length: 113, dtype: float64\n",
      "\n",
      "\n",
      "Number of unique items in Medical_History_2 are  522\n"
     ]
    }
   ],
   "source": [
    "#we need to remove one hot encoded data from training- dont need to check variance and inlude it for standardization of data.Then recombine them before making the model. \n",
    "X_train_on_hot=X_train[col_one_hot]\n",
    "X_train=X_train.drop(col_one_hot,axis=1)\n",
    "X_test_on_hot=X_test[col_one_hot]\n",
    "X_test=X_test.drop(col_one_hot,axis=1)\n",
    "\n",
    "print(X_train.var().sort_values(ascending=False))\n",
    "print(\"\\n\\nNumber of unique items in Medical_History_2 are \",X_train['Medical_History_2'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9519a03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T09:41:40.601588Z",
     "iopub.status.busy": "2022-10-20T09:41:40.600504Z",
     "iopub.status.idle": "2022-10-20T09:41:40.610745Z",
     "shell.execute_reply": "2022-10-20T09:41:40.609323Z"
    },
    "papermill": {
     "duration": 0.024029,
     "end_time": "2022-10-20T09:41:40.613779",
     "exception": false,
     "start_time": "2022-10-20T09:41:40.589750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for Nan here in X_train\n",
    "X_train.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72f71d3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T09:41:40.634126Z",
     "iopub.status.busy": "2022-10-20T09:41:40.633110Z",
     "iopub.status.idle": "2022-10-20T09:41:40.678954Z",
     "shell.execute_reply": "2022-10-20T09:41:40.677923Z"
    },
    "papermill": {
     "duration": 0.05889,
     "end_time": "2022-10-20T09:41:40.681956",
     "exception": false,
     "start_time": "2022-10-20T09:41:40.623066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total 8 features selected by setting minimum required varince to 0.8, these are ['Medical_History_2', 'Product_Info_3', 'Employment_Info_2', 'InsuredInfo_3', 'Insurance_History_3', 'Insurance_History_7', 'Insurance_History_4', 'Medical_History_41']\n"
     ]
    }
   ],
   "source": [
    "#selecting features which have variance greater than 0.8\n",
    "fea_sort=X_train.var().sort_values(ascending=False)\n",
    "\n",
    "#defining an array which would store features with high variance\n",
    "fea_hig_var=[]\n",
    "\n",
    "#minimum required threshold variance of a feature \n",
    "minimum_var=0.8\n",
    "i=0\n",
    "while fea_sort[i]>minimum_var:\n",
    "    fea_hig_var.append(fea_sort.index[i])\n",
    "    i=i+1\n",
    "        \n",
    "print('\\nTotal {} features selected by setting minimum required varince to {}, these are {}'.format(i,minimum_var,fea_hig_var) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93be66d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T09:41:40.700794Z",
     "iopub.status.busy": "2022-10-20T09:41:40.699937Z",
     "iopub.status.idle": "2022-10-20T09:41:40.708151Z",
     "shell.execute_reply": "2022-10-20T09:41:40.706936Z"
    },
    "papermill": {
     "duration": 0.020195,
     "end_time": "2022-10-20T09:41:40.710416",
     "exception": false,
     "start_time": "2022-10-20T09:41:40.690221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#we select the high varince features for train and test\n",
    "X_train_high=X_train[fea_hig_var]\n",
    "X_test_high=X_test[fea_hig_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc73340f",
   "metadata": {
    "papermill": {
     "duration": 0.008795,
     "end_time": "2022-10-20T09:41:40.728501",
     "exception": false,
     "start_time": "2022-10-20T09:41:40.719706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***Here we standardize the data*** then concat one hot encoded labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02fcddac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T09:41:40.748393Z",
     "iopub.status.busy": "2022-10-20T09:41:40.747223Z",
     "iopub.status.idle": "2022-10-20T09:41:40.757537Z",
     "shell.execute_reply": "2022-10-20T09:41:40.756485Z"
    },
    "papermill": {
     "duration": 0.022037,
     "end_time": "2022-10-20T09:41:40.759772",
     "exception": false,
     "start_time": "2022-10-20T09:41:40.737735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check X_train_high ad X_test_high nan here\n",
    "X_train_high.isna().any().sum(),X_test_high.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fd3e163",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T09:41:40.779526Z",
     "iopub.status.busy": "2022-10-20T09:41:40.778802Z",
     "iopub.status.idle": "2022-10-20T09:41:40.813427Z",
     "shell.execute_reply": "2022-10-20T09:41:40.812331Z"
    },
    "papermill": {
     "duration": 0.047446,
     "end_time": "2022-10-20T09:41:40.816042",
     "exception": false,
     "start_time": "2022-10-20T09:41:40.768596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_train_fit=pd.DataFrame(scaler.fit_transform(X_train_high),columns=fea_hig_var)\n",
    "X_test_fit=pd.DataFrame(scaler.fit_transform(X_test_high),columns=fea_hig_var)\n",
    "\n",
    "#now we concatenate one hot encoded data into X_train-reset_ndex to clear index values and then remove the inde column after concat\n",
    "\n",
    "X_train_cat=pd.concat([X_train_fit.reset_index(),X_train_on_hot.reset_index()],axis=1).drop(['index'],axis=1)\n",
    "X_test_cat=pd.concat((X_test_fit.reset_index(),X_test_on_hot.reset_index()),axis=1).drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15576069",
   "metadata": {
    "papermill": {
     "duration": 0.008748,
     "end_time": "2022-10-20T09:41:40.833586",
     "exception": false,
     "start_time": "2022-10-20T09:41:40.824838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***Start the model training from here***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32f851e",
   "metadata": {
    "papermill": {
     "duration": 0.00803,
     "end_time": "2022-10-20T09:41:40.850314",
     "exception": false,
     "start_time": "2022-10-20T09:41:40.842284",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***First model- KNN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed06b467",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T09:41:40.869288Z",
     "iopub.status.busy": "2022-10-20T09:41:40.868699Z",
     "iopub.status.idle": "2022-10-20T09:41:57.013109Z",
     "shell.execute_reply": "2022-10-20T09:41:57.011817Z"
    },
    "papermill": {
     "duration": 16.157082,
     "end_time": "2022-10-20T09:41:57.015742",
     "exception": false,
     "start_time": "2022-10-20T09:41:40.858660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn_model=KNeighborsClassifier(10)\n",
    "knn_model=knn_model.fit(X_train_cat,y_train)\n",
    "y_pred=knn_model.predict(X_test_cat)\n",
    "print(len(np.unique(y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "999fcf3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T09:41:57.034886Z",
     "iopub.status.busy": "2022-10-20T09:41:57.034459Z",
     "iopub.status.idle": "2022-10-20T09:41:57.041965Z",
     "shell.execute_reply": "2022-10-20T09:41:57.040662Z"
    },
    "papermill": {
     "duration": 0.020654,
     "end_time": "2022-10-20T09:41:57.045045",
     "exception": false,
     "start_time": "2022-10-20T09:41:57.024391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2956215554194734\n"
     ]
    }
   ],
   "source": [
    "score=accuracy_score(y_test,y_pred)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f477f84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T09:41:57.065303Z",
     "iopub.status.busy": "2022-10-20T09:41:57.064468Z",
     "iopub.status.idle": "2022-10-20T09:42:01.162237Z",
     "shell.execute_reply": "2022-10-20T09:42:01.160712Z"
    },
    "papermill": {
     "duration": 4.110886,
     "end_time": "2022-10-20T09:42:01.164943",
     "exception": false,
     "start_time": "2022-10-20T09:41:57.054057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=50, max_depth=40, criterion = 'entropy', \n",
    "                            min_samples_leaf= 1,min_samples_split= 2)\n",
    "rf=rf.fit(X_train_cat,y_train)\n",
    "y_pred=rf.predict(X_test_cat)\n",
    "print(len(np.unique(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ae9d888",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T09:42:01.184655Z",
     "iopub.status.busy": "2022-10-20T09:42:01.184184Z",
     "iopub.status.idle": "2022-10-20T09:42:02.380295Z",
     "shell.execute_reply": "2022-10-20T09:42:02.378595Z"
    },
    "papermill": {
     "duration": 1.209179,
     "end_time": "2022-10-20T09:42:02.383005",
     "exception": false,
     "start_time": "2022-10-20T09:42:01.173826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6869171798416489\n",
      "0.28021024698918146\n"
     ]
    }
   ],
   "source": [
    "y_predict_train_rf = rf.predict(X_train_cat)\n",
    "y_predict_test_rf = rf.predict(X_test_cat)\n",
    "\n",
    "train_accuracy_score_rf = accuracy_score(y_train, y_predict_train_rf)\n",
    "test_accuracy_score_rf = accuracy_score(y_test, y_predict_test_rf)\n",
    "\n",
    "print(train_accuracy_score_rf)\n",
    "print(test_accuracy_score_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca36ce4d",
   "metadata": {
    "papermill": {
     "duration": 0.00837,
     "end_time": "2022-10-20T09:42:02.400175",
     "exception": false,
     "start_time": "2022-10-20T09:42:02.391805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35.192347,
   "end_time": "2022-10-20T09:42:03.232576",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-20T09:41:28.040229",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
